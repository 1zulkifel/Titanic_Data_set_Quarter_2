{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>138</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>139</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>140</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>141</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "130  131            7.4           2.8            6.1           1.9   \n",
       "131  132            7.9           3.8            6.4           2.0   \n",
       "132  133            6.4           2.8            5.6           2.2   \n",
       "133  134            6.3           2.8            5.1           1.5   \n",
       "134  135            6.1           2.6            5.6           1.4   \n",
       "135  136            7.7           3.0            6.1           2.3   \n",
       "136  137            6.3           3.4            5.6           2.4   \n",
       "137  138            6.4           3.1            5.5           1.8   \n",
       "138  139            6.0           3.0            4.8           1.8   \n",
       "139  140            6.9           3.1            5.4           2.1   \n",
       "140  141            6.7           3.1            5.6           2.4   \n",
       "141  142            6.9           3.1            5.1           2.3   \n",
       "142  143            5.8           2.7            5.1           1.9   \n",
       "143  144            6.8           3.2            5.9           2.3   \n",
       "144  145            6.7           3.3            5.7           2.5   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "130  Iris-virginica  \n",
       "131  Iris-virginica  \n",
       "132  Iris-virginica  \n",
       "133  Iris-virginica  \n",
       "134  Iris-virginica  \n",
       "135  Iris-virginica  \n",
       "136  Iris-virginica  \n",
       "137  Iris-virginica  \n",
       "138  Iris-virginica  \n",
       "139  Iris-virginica  \n",
       "140  Iris-virginica  \n",
       "141  Iris-virginica  \n",
       "142  Iris-virginica  \n",
       "143  Iris-virginica  \n",
       "144  Iris-virginica  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./iris/irs.csv')\n",
    "data = df\n",
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f235a2f3450>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.corr().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2359f78750>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[['SepalWidthCm','PetalWidthCm']].corr().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0            1                0               0\n",
       "1            1                0               0\n",
       "2            1                0               0\n",
       "3            1                0               0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=data[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm',]]\n",
    "Y=pd.get_dummies(data['Species'])\n",
    "Y.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='relu',input_shape=(4,)))\n",
    "model.add(Dense(1000, activation='sigmoid',))\n",
    "model.add(Dense(500, activation='sigmoid',))\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 1000)              5000      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 1503      \n",
      "=================================================================\n",
      "Total params: 1,508,003\n",
      "Trainable params: 1,508,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.8),loss='categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/250\n",
      "150/150 [==============================] - 0s 2ms/sample - loss: 13.3640 - acc: 0.3200\n",
      "Epoch 2/250\n",
      "150/150 [==============================] - 0s 476us/sample - loss: 4.6748 - acc: 0.3067\n",
      "Epoch 3/250\n",
      "150/150 [==============================] - 0s 467us/sample - loss: 1.1211 - acc: 0.3333\n",
      "Epoch 4/250\n",
      "150/150 [==============================] - 0s 557us/sample - loss: 1.0891 - acc: 0.3333\n",
      "Epoch 5/250\n",
      "150/150 [==============================] - 0s 445us/sample - loss: 1.0831 - acc: 0.3867\n",
      "Epoch 6/250\n",
      "150/150 [==============================] - 0s 440us/sample - loss: 1.0807 - acc: 0.3333\n",
      "Epoch 7/250\n",
      "150/150 [==============================] - 0s 555us/sample - loss: 1.0790 - acc: 0.4467\n",
      "Epoch 8/250\n",
      "150/150 [==============================] - 0s 442us/sample - loss: 1.0804 - acc: 0.3600\n",
      "Epoch 9/250\n",
      "150/150 [==============================] - 0s 506us/sample - loss: 1.0767 - acc: 0.4267\n",
      "Epoch 10/250\n",
      "150/150 [==============================] - 0s 551us/sample - loss: 1.0743 - acc: 0.6000\n",
      "Epoch 11/250\n",
      "150/150 [==============================] - 0s 479us/sample - loss: 1.0722 - acc: 0.6267\n",
      "Epoch 12/250\n",
      "150/150 [==============================] - 0s 461us/sample - loss: 1.0760 - acc: 0.6667\n",
      "Epoch 13/250\n",
      "150/150 [==============================] - 0s 541us/sample - loss: 1.0678 - acc: 0.5800\n",
      "Epoch 14/250\n",
      "150/150 [==============================] - 0s 501us/sample - loss: 1.0712 - acc: 0.5000\n",
      "Epoch 15/250\n",
      "150/150 [==============================] - 0s 466us/sample - loss: 1.0663 - acc: 0.5000\n",
      "Epoch 16/250\n",
      "150/150 [==============================] - 0s 535us/sample - loss: 1.0631 - acc: 0.3933\n",
      "Epoch 17/250\n",
      "150/150 [==============================] - 0s 461us/sample - loss: 1.0540 - acc: 0.6267\n",
      "Epoch 18/250\n",
      "150/150 [==============================] - 0s 490us/sample - loss: 1.0479 - acc: 0.7400\n",
      "Epoch 19/250\n",
      "150/150 [==============================] - 0s 565us/sample - loss: 1.0462 - acc: 0.6600\n",
      "Epoch 20/250\n",
      "150/150 [==============================] - 0s 460us/sample - loss: 1.0372 - acc: 0.4467\n",
      "Epoch 21/250\n",
      "150/150 [==============================] - 0s 465us/sample - loss: 1.0301 - acc: 0.6800\n",
      "Epoch 22/250\n",
      "150/150 [==============================] - 0s 591us/sample - loss: 1.0168 - acc: 0.4867\n",
      "Epoch 23/250\n",
      "150/150 [==============================] - 0s 465us/sample - loss: 1.0019 - acc: 0.6067\n",
      "Epoch 24/250\n",
      "150/150 [==============================] - 0s 448us/sample - loss: 0.9932 - acc: 0.6600\n",
      "Epoch 25/250\n",
      "150/150 [==============================] - 0s 574us/sample - loss: 0.9642 - acc: 0.5267\n",
      "Epoch 26/250\n",
      "150/150 [==============================] - 0s 515us/sample - loss: 0.9386 - acc: 0.7200\n",
      "Epoch 27/250\n",
      "150/150 [==============================] - 0s 446us/sample - loss: 0.9185 - acc: 0.5933\n",
      "Epoch 28/250\n",
      "150/150 [==============================] - 0s 551us/sample - loss: 0.8731 - acc: 0.6267\n",
      "Epoch 29/250\n",
      "150/150 [==============================] - 0s 503us/sample - loss: 0.8268 - acc: 0.7133\n",
      "Epoch 30/250\n",
      "150/150 [==============================] - 0s 493us/sample - loss: 0.8017 - acc: 0.6733\n",
      "Epoch 31/250\n",
      "150/150 [==============================] - 0s 544us/sample - loss: 0.9584 - acc: 0.3400\n",
      "Epoch 32/250\n",
      "150/150 [==============================] - 0s 508us/sample - loss: 0.8024 - acc: 0.6467\n",
      "Epoch 33/250\n",
      "150/150 [==============================] - 0s 451us/sample - loss: 0.7848 - acc: 0.6533\n",
      "Epoch 34/250\n",
      "150/150 [==============================] - 0s 574us/sample - loss: 0.7083 - acc: 0.7867\n",
      "Epoch 35/250\n",
      "150/150 [==============================] - 0s 469us/sample - loss: 0.6391 - acc: 0.7933\n",
      "Epoch 36/250\n",
      "150/150 [==============================] - 0s 463us/sample - loss: 0.5974 - acc: 0.8933\n",
      "Epoch 37/250\n",
      "150/150 [==============================] - 0s 529us/sample - loss: 0.5966 - acc: 0.7267\n",
      "Epoch 38/250\n",
      "150/150 [==============================] - 0s 520us/sample - loss: 0.6686 - acc: 0.6667\n",
      "Epoch 39/250\n",
      "150/150 [==============================] - 0s 450us/sample - loss: 0.6981 - acc: 0.6467\n",
      "Epoch 40/250\n",
      "150/150 [==============================] - 0s 593us/sample - loss: 0.5139 - acc: 0.8067\n",
      "Epoch 41/250\n",
      "150/150 [==============================] - 0s 475us/sample - loss: 0.4834 - acc: 0.9600\n",
      "Epoch 42/250\n",
      "150/150 [==============================] - 0s 478us/sample - loss: 0.4658 - acc: 0.9533\n",
      "Epoch 43/250\n",
      "150/150 [==============================] - 0s 535us/sample - loss: 0.4527 - acc: 0.9667\n",
      "Epoch 44/250\n",
      "150/150 [==============================] - 0s 490us/sample - loss: 0.4441 - acc: 0.9400\n",
      "Epoch 45/250\n",
      "150/150 [==============================] - 0s 467us/sample - loss: 0.4519 - acc: 0.8333\n",
      "Epoch 46/250\n",
      "150/150 [==============================] - 0s 557us/sample - loss: 0.4434 - acc: 0.8400\n",
      "Epoch 47/250\n",
      "150/150 [==============================] - 0s 468us/sample - loss: 0.4174 - acc: 0.9400\n",
      "Epoch 48/250\n",
      "150/150 [==============================] - 0s 479us/sample - loss: 0.4102 - acc: 0.8800\n",
      "Epoch 49/250\n",
      "150/150 [==============================] - 0s 546us/sample - loss: 0.3882 - acc: 0.9733\n",
      "Epoch 50/250\n",
      "150/150 [==============================] - 0s 479us/sample - loss: 0.3770 - acc: 0.9667\n",
      "Epoch 51/250\n",
      "150/150 [==============================] - 0s 479us/sample - loss: 0.3788 - acc: 0.9267\n",
      "Epoch 52/250\n",
      "150/150 [==============================] - 0s 529us/sample - loss: 0.4062 - acc: 0.8067\n",
      "Epoch 53/250\n",
      "150/150 [==============================] - 0s 496us/sample - loss: 0.3851 - acc: 0.8133\n",
      "Epoch 54/250\n",
      "150/150 [==============================] - 0s 492us/sample - loss: 0.4098 - acc: 0.8267\n",
      "Epoch 55/250\n",
      "150/150 [==============================] - 0s 561us/sample - loss: 0.3477 - acc: 0.8933\n",
      "Epoch 56/250\n",
      "150/150 [==============================] - 0s 486us/sample - loss: 0.4515 - acc: 0.7200\n",
      "Epoch 57/250\n",
      "150/150 [==============================] - 0s 485us/sample - loss: 0.3275 - acc: 0.9467\n",
      "Epoch 58/250\n",
      "150/150 [==============================] - 0s 551us/sample - loss: 0.3100 - acc: 0.9400\n",
      "Epoch 59/250\n",
      "150/150 [==============================] - 0s 550us/sample - loss: 0.4716 - acc: 0.7533\n",
      "Epoch 60/250\n",
      "150/150 [==============================] - 0s 531us/sample - loss: 0.3136 - acc: 0.9267\n",
      "Epoch 61/250\n",
      "150/150 [==============================] - 0s 588us/sample - loss: 0.3575 - acc: 0.8067\n",
      "Epoch 62/250\n",
      "150/150 [==============================] - 0s 590us/sample - loss: 0.6487 - acc: 0.5800\n",
      "Epoch 63/250\n",
      "150/150 [==============================] - 0s 581us/sample - loss: 2.3171 - acc: 0.3333\n",
      "Epoch 64/250\n",
      "150/150 [==============================] - 0s 582us/sample - loss: 0.8622 - acc: 0.5400\n",
      "Epoch 65/250\n",
      "150/150 [==============================] - 0s 563us/sample - loss: 0.4416 - acc: 0.8400\n",
      "Epoch 66/250\n",
      "150/150 [==============================] - 0s 597us/sample - loss: 0.4216 - acc: 0.9067\n",
      "Epoch 67/250\n",
      "150/150 [==============================] - 0s 487us/sample - loss: 0.4023 - acc: 0.9467\n",
      "Epoch 68/250\n",
      "150/150 [==============================] - 0s 613us/sample - loss: 0.3831 - acc: 0.9800\n",
      "Epoch 69/250\n",
      "150/150 [==============================] - 0s 496us/sample - loss: 0.3692 - acc: 0.9667\n",
      "Epoch 70/250\n",
      "150/150 [==============================] - 0s 541us/sample - loss: 0.3849 - acc: 0.8533\n",
      "Epoch 71/250\n",
      "150/150 [==============================] - 0s 493us/sample - loss: 0.3566 - acc: 0.8733\n",
      "Epoch 72/250\n",
      "150/150 [==============================] - 0s 616us/sample - loss: 0.3374 - acc: 0.9467\n",
      "Epoch 73/250\n",
      "150/150 [==============================] - 0s 530us/sample - loss: 0.4198 - acc: 0.7400\n",
      "Epoch 74/250\n",
      "150/150 [==============================] - 0s 587us/sample - loss: 0.3141 - acc: 0.9600\n",
      "Epoch 75/250\n",
      "150/150 [==============================] - 0s 571us/sample - loss: 0.3065 - acc: 0.9467\n",
      "Epoch 76/250\n",
      "150/150 [==============================] - 0s 606us/sample - loss: 0.2860 - acc: 0.9600\n",
      "Epoch 77/250\n",
      "150/150 [==============================] - 0s 563us/sample - loss: 0.3260 - acc: 0.8467\n",
      "Epoch 78/250\n",
      "150/150 [==============================] - 0s 611us/sample - loss: 0.3570 - acc: 0.8533\n",
      "Epoch 79/250\n",
      "150/150 [==============================] - 0s 491us/sample - loss: 0.4290 - acc: 0.7600\n",
      "Epoch 80/250\n",
      "150/150 [==============================] - 0s 517us/sample - loss: 0.2970 - acc: 0.9067\n",
      "Epoch 81/250\n",
      "150/150 [==============================] - 0s 548us/sample - loss: 0.3545 - acc: 0.8200\n",
      "Epoch 82/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 557us/sample - loss: 0.3512 - acc: 0.8133\n",
      "Epoch 83/250\n",
      "150/150 [==============================] - 0s 412us/sample - loss: 0.5220 - acc: 0.6867\n",
      "Epoch 84/250\n",
      "150/150 [==============================] - 0s 412us/sample - loss: 0.2802 - acc: 0.9467\n",
      "Epoch 85/250\n",
      "150/150 [==============================] - 0s 477us/sample - loss: 0.2657 - acc: 0.9400\n",
      "Epoch 86/250\n",
      "150/150 [==============================] - 0s 474us/sample - loss: 0.2867 - acc: 0.9067\n",
      "Epoch 87/250\n",
      "150/150 [==============================] - 0s 428us/sample - loss: 0.3568 - acc: 0.8333\n",
      "Epoch 88/250\n",
      "150/150 [==============================] - 0s 450us/sample - loss: 0.3369 - acc: 0.7800\n",
      "Epoch 89/250\n",
      "150/150 [==============================] - 0s 436us/sample - loss: 0.2329 - acc: 0.9800\n",
      "Epoch 90/250\n",
      "150/150 [==============================] - 0s 502us/sample - loss: 0.2279 - acc: 0.9667\n",
      "Epoch 91/250\n",
      "150/150 [==============================] - 0s 462us/sample - loss: 0.5126 - acc: 0.7267\n",
      "Epoch 92/250\n",
      "150/150 [==============================] - 0s 535us/sample - loss: 1.5550 - acc: 0.4800\n",
      "Epoch 93/250\n",
      "150/150 [==============================] - 0s 726us/sample - loss: 0.4950 - acc: 0.6733\n",
      "Epoch 94/250\n",
      "150/150 [==============================] - 0s 600us/sample - loss: 0.3655 - acc: 0.8467\n",
      "Epoch 95/250\n",
      "150/150 [==============================] - 0s 439us/sample - loss: 0.3092 - acc: 0.9400\n",
      "Epoch 96/250\n",
      "150/150 [==============================] - 0s 441us/sample - loss: 0.2944 - acc: 0.8933\n",
      "Epoch 97/250\n",
      "150/150 [==============================] - 0s 475us/sample - loss: 0.2594 - acc: 0.9733\n",
      "Epoch 98/250\n",
      "150/150 [==============================] - 0s 427us/sample - loss: 0.2516 - acc: 0.9533\n",
      "Epoch 99/250\n",
      "150/150 [==============================] - 0s 417us/sample - loss: 0.2517 - acc: 0.9200\n",
      "Epoch 100/250\n",
      "150/150 [==============================] - 0s 441us/sample - loss: 0.2409 - acc: 0.9400\n",
      "Epoch 101/250\n",
      "150/150 [==============================] - 0s 508us/sample - loss: 0.2855 - acc: 0.8800\n",
      "Epoch 102/250\n",
      "150/150 [==============================] - 0s 433us/sample - loss: 0.4303 - acc: 0.7667\n",
      "Epoch 103/250\n",
      "150/150 [==============================] - 0s 512us/sample - loss: 0.3641 - acc: 0.7533\n",
      "Epoch 104/250\n",
      "150/150 [==============================] - 0s 480us/sample - loss: 0.2640 - acc: 0.9000\n",
      "Epoch 105/250\n",
      "150/150 [==============================] - 0s 437us/sample - loss: 0.2064 - acc: 0.9800\n",
      "Epoch 106/250\n",
      "150/150 [==============================] - 0s 477us/sample - loss: 0.1922 - acc: 0.9867\n",
      "Epoch 107/250\n",
      "150/150 [==============================] - 0s 531us/sample - loss: 0.1817 - acc: 0.9733\n",
      "Epoch 108/250\n",
      "150/150 [==============================] - 0s 443us/sample - loss: 0.1762 - acc: 0.9733\n",
      "Epoch 109/250\n",
      "150/150 [==============================] - 0s 459us/sample - loss: 0.2759 - acc: 0.8667\n",
      "Epoch 110/250\n",
      "150/150 [==============================] - 0s 512us/sample - loss: 0.5516 - acc: 0.7600\n",
      "Epoch 111/250\n",
      "150/150 [==============================] - 0s 555us/sample - loss: 0.3686 - acc: 0.7867\n",
      "Epoch 112/250\n",
      "150/150 [==============================] - 0s 485us/sample - loss: 0.3004 - acc: 0.8467\n",
      "Epoch 113/250\n",
      "150/150 [==============================] - 0s 444us/sample - loss: 0.1983 - acc: 0.9667\n",
      "Epoch 114/250\n",
      "150/150 [==============================] - 0s 442us/sample - loss: 0.1847 - acc: 0.9667\n",
      "Epoch 115/250\n",
      "150/150 [==============================] - 0s 495us/sample - loss: 0.1711 - acc: 0.9867\n",
      "Epoch 116/250\n",
      "150/150 [==============================] - 0s 451us/sample - loss: 0.1914 - acc: 0.9600\n",
      "Epoch 117/250\n",
      "150/150 [==============================] - 0s 447us/sample - loss: 1.1645 - acc: 0.5067\n",
      "Epoch 118/250\n",
      "150/150 [==============================] - 0s 479us/sample - loss: 0.6087 - acc: 0.6800\n",
      "Epoch 119/250\n",
      "150/150 [==============================] - 0s 411us/sample - loss: 0.2576 - acc: 0.9200\n",
      "Epoch 120/250\n",
      "150/150 [==============================] - 0s 422us/sample - loss: 0.2294 - acc: 0.9667\n",
      "Epoch 121/250\n",
      "150/150 [==============================] - 0s 534us/sample - loss: 0.2896 - acc: 0.9000\n",
      "Epoch 122/250\n",
      "150/150 [==============================] - 0s 457us/sample - loss: 0.4448 - acc: 0.7067\n",
      "Epoch 123/250\n",
      "150/150 [==============================] - 0s 440us/sample - loss: 0.2279 - acc: 0.9867\n",
      "Epoch 124/250\n",
      "150/150 [==============================] - 0s 501us/sample - loss: 0.2110 - acc: 0.9600\n",
      "Epoch 125/250\n",
      "150/150 [==============================] - 0s 639us/sample - loss: 0.1979 - acc: 0.9667\n",
      "Epoch 126/250\n",
      "150/150 [==============================] - 0s 662us/sample - loss: 0.2708 - acc: 0.8667\n",
      "Epoch 127/250\n",
      "150/150 [==============================] - 0s 473us/sample - loss: 0.5199 - acc: 0.7333\n",
      "Epoch 128/250\n",
      "150/150 [==============================] - 0s 448us/sample - loss: 0.3276 - acc: 0.8467\n",
      "Epoch 129/250\n",
      "150/150 [==============================] - 0s 521us/sample - loss: 0.2122 - acc: 0.9600\n",
      "Epoch 130/250\n",
      "150/150 [==============================] - 0s 513us/sample - loss: 0.1906 - acc: 0.9667\n",
      "Epoch 131/250\n",
      "150/150 [==============================] - 0s 697us/sample - loss: 0.1951 - acc: 0.9600\n",
      "Epoch 132/250\n",
      "150/150 [==============================] - 0s 597us/sample - loss: 0.2674 - acc: 0.8800\n",
      "Epoch 133/250\n",
      "150/150 [==============================] - 0s 499us/sample - loss: 0.4154 - acc: 0.7800\n",
      "Epoch 134/250\n",
      "150/150 [==============================] - 0s 758us/sample - loss: 0.2210 - acc: 0.9400\n",
      "Epoch 135/250\n",
      "150/150 [==============================] - 0s 561us/sample - loss: 0.1939 - acc: 0.9467\n",
      "Epoch 136/250\n",
      "150/150 [==============================] - 0s 462us/sample - loss: 0.2655 - acc: 0.8600\n",
      "Epoch 137/250\n",
      "150/150 [==============================] - 0s 760us/sample - loss: 0.4964 - acc: 0.7733\n",
      "Epoch 138/250\n",
      "150/150 [==============================] - 0s 649us/sample - loss: 0.3055 - acc: 0.8533\n",
      "Epoch 139/250\n",
      "150/150 [==============================] - 0s 500us/sample - loss: 0.1787 - acc: 0.9600\n",
      "Epoch 140/250\n",
      "150/150 [==============================] - 0s 565us/sample - loss: 0.1704 - acc: 0.9733\n",
      "Epoch 141/250\n",
      "150/150 [==============================] - 0s 498us/sample - loss: 0.3004 - acc: 0.8400\n",
      "Epoch 142/250\n",
      "150/150 [==============================] - 0s 498us/sample - loss: 0.5298 - acc: 0.7467\n",
      "Epoch 143/250\n",
      "150/150 [==============================] - 0s 594us/sample - loss: 0.3755 - acc: 0.8000\n",
      "Epoch 144/250\n",
      "150/150 [==============================] - 0s 461us/sample - loss: 0.2060 - acc: 0.9400\n",
      "Epoch 145/250\n",
      "150/150 [==============================] - 0s 467us/sample - loss: 0.1754 - acc: 0.9733\n",
      "Epoch 146/250\n",
      "150/150 [==============================] - 0s 553us/sample - loss: 0.1609 - acc: 0.9733\n",
      "Epoch 147/250\n",
      "150/150 [==============================] - 0s 544us/sample - loss: 0.1654 - acc: 0.9600\n",
      "Epoch 148/250\n",
      "150/150 [==============================] - 0s 482us/sample - loss: 0.3340 - acc: 0.8400\n",
      "Epoch 149/250\n",
      "150/150 [==============================] - 0s 501us/sample - loss: 0.6678 - acc: 0.6667\n",
      "Epoch 150/250\n",
      "150/150 [==============================] - 0s 510us/sample - loss: 0.2998 - acc: 0.8667\n",
      "Epoch 151/250\n",
      "150/150 [==============================] - 0s 579us/sample - loss: 0.1964 - acc: 0.9600\n",
      "Epoch 152/250\n",
      "150/150 [==============================] - 0s 504us/sample - loss: 0.1870 - acc: 0.9533\n",
      "Epoch 153/250\n",
      "150/150 [==============================] - 0s 540us/sample - loss: 0.1809 - acc: 0.9400\n",
      "Epoch 154/250\n",
      "150/150 [==============================] - 0s 484us/sample - loss: 0.2354 - acc: 0.9200\n",
      "Epoch 155/250\n",
      "150/150 [==============================] - 0s 528us/sample - loss: 0.4000 - acc: 0.7800\n",
      "Epoch 156/250\n",
      "150/150 [==============================] - 0s 613us/sample - loss: 0.3631 - acc: 0.7800\n",
      "Epoch 157/250\n",
      "150/150 [==============================] - 0s 452us/sample - loss: 0.1976 - acc: 0.9400\n",
      "Epoch 158/250\n",
      "150/150 [==============================] - 0s 596us/sample - loss: 0.1783 - acc: 0.9400\n",
      "Epoch 159/250\n",
      "150/150 [==============================] - 0s 534us/sample - loss: 0.2506 - acc: 0.8800\n",
      "Epoch 160/250\n",
      "150/150 [==============================] - 0s 567us/sample - loss: 0.3079 - acc: 0.8400\n",
      "Epoch 161/250\n",
      "150/150 [==============================] - 0s 625us/sample - loss: 0.1587 - acc: 0.9533\n",
      "Epoch 162/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 519us/sample - loss: 0.1652 - acc: 0.9467\n",
      "Epoch 163/250\n",
      "150/150 [==============================] - 0s 507us/sample - loss: 0.2881 - acc: 0.8533\n",
      "Epoch 164/250\n",
      "150/150 [==============================] - 0s 424us/sample - loss: 0.1373 - acc: 0.9867\n",
      "Epoch 165/250\n",
      "150/150 [==============================] - 0s 498us/sample - loss: 0.1518 - acc: 0.9533\n",
      "Epoch 166/250\n",
      "150/150 [==============================] - 0s 473us/sample - loss: 0.2325 - acc: 0.9067\n",
      "Epoch 167/250\n",
      "150/150 [==============================] - 0s 447us/sample - loss: 0.4263 - acc: 0.7867\n",
      "Epoch 168/250\n",
      "150/150 [==============================] - 0s 428us/sample - loss: 0.4002 - acc: 0.7933\n",
      "Epoch 169/250\n",
      "150/150 [==============================] - 0s 487us/sample - loss: 0.2072 - acc: 0.9133\n",
      "Epoch 170/250\n",
      "150/150 [==============================] - 0s 441us/sample - loss: 0.1499 - acc: 0.9800\n",
      "Epoch 171/250\n",
      "150/150 [==============================] - 0s 489us/sample - loss: 0.1726 - acc: 0.9533\n",
      "Epoch 172/250\n",
      "150/150 [==============================] - 0s 484us/sample - loss: 0.2725 - acc: 0.8867\n",
      "Epoch 173/250\n",
      "150/150 [==============================] - 0s 433us/sample - loss: 0.3484 - acc: 0.8467\n",
      "Epoch 174/250\n",
      "150/150 [==============================] - 0s 491us/sample - loss: 0.1320 - acc: 0.9733\n",
      "Epoch 175/250\n",
      "150/150 [==============================] - 0s 494us/sample - loss: 0.1289 - acc: 0.9800\n",
      "Epoch 176/250\n",
      "150/150 [==============================] - 0s 419us/sample - loss: 0.1592 - acc: 0.9467\n",
      "Epoch 177/250\n",
      "150/150 [==============================] - 0s 450us/sample - loss: 0.3950 - acc: 0.8000\n",
      "Epoch 178/250\n",
      "150/150 [==============================] - 0s 444us/sample - loss: 0.1284 - acc: 0.9800\n",
      "Epoch 179/250\n",
      "150/150 [==============================] - 0s 445us/sample - loss: 0.1970 - acc: 0.9067\n",
      "Epoch 180/250\n",
      "150/150 [==============================] - 0s 480us/sample - loss: 1.1703 - acc: 0.5467\n",
      "Epoch 181/250\n",
      "150/150 [==============================] - 0s 458us/sample - loss: 0.7876 - acc: 0.6667\n",
      "Epoch 182/250\n",
      "150/150 [==============================] - 0s 471us/sample - loss: 0.5567 - acc: 0.6667\n",
      "Epoch 183/250\n",
      "150/150 [==============================] - 0s 469us/sample - loss: 0.4040 - acc: 0.7467\n",
      "Epoch 184/250\n",
      "150/150 [==============================] - 0s 458us/sample - loss: 0.3151 - acc: 0.9467\n",
      "Epoch 185/250\n",
      "150/150 [==============================] - 0s 429us/sample - loss: 0.2977 - acc: 0.9200\n",
      "Epoch 186/250\n",
      "150/150 [==============================] - 0s 438us/sample - loss: 0.2707 - acc: 0.9600\n",
      "Epoch 187/250\n",
      "150/150 [==============================] - 0s 413us/sample - loss: 0.2729 - acc: 0.9267\n",
      "Epoch 188/250\n",
      "150/150 [==============================] - 0s 460us/sample - loss: 0.2886 - acc: 0.9067\n",
      "Epoch 189/250\n",
      "150/150 [==============================] - 0s 511us/sample - loss: 0.2410 - acc: 0.9467\n",
      "Epoch 190/250\n",
      "150/150 [==============================] - 0s 433us/sample - loss: 0.2161 - acc: 0.9600\n",
      "Epoch 191/250\n",
      "150/150 [==============================] - 0s 438us/sample - loss: 0.1934 - acc: 0.9733\n",
      "Epoch 192/250\n",
      "150/150 [==============================] - 0s 429us/sample - loss: 0.1991 - acc: 0.9600\n",
      "Epoch 193/250\n",
      "150/150 [==============================] - 0s 446us/sample - loss: 0.2853 - acc: 0.8533\n",
      "Epoch 194/250\n",
      "150/150 [==============================] - 0s 432us/sample - loss: 0.1891 - acc: 0.9667\n",
      "Epoch 195/250\n",
      "150/150 [==============================] - 0s 452us/sample - loss: 0.2254 - acc: 0.9067\n",
      "Epoch 196/250\n",
      "150/150 [==============================] - 0s 529us/sample - loss: 0.1660 - acc: 0.9733\n",
      "Epoch 197/250\n",
      "150/150 [==============================] - 0s 486us/sample - loss: 0.2579 - acc: 0.8600\n",
      "Epoch 198/250\n",
      "150/150 [==============================] - 0s 487us/sample - loss: 0.2405 - acc: 0.8867\n",
      "Epoch 199/250\n",
      "150/150 [==============================] - 0s 466us/sample - loss: 0.1680 - acc: 0.9400\n",
      "Epoch 200/250\n",
      "150/150 [==============================] - 0s 513us/sample - loss: 0.1683 - acc: 0.9333\n",
      "Epoch 201/250\n",
      "150/150 [==============================] - 0s 463us/sample - loss: 0.2805 - acc: 0.8733\n",
      "Epoch 202/250\n",
      "150/150 [==============================] - 0s 460us/sample - loss: 0.1376 - acc: 0.9533\n",
      "Epoch 203/250\n",
      "150/150 [==============================] - 0s 479us/sample - loss: 0.1194 - acc: 0.9800\n",
      "Epoch 204/250\n",
      "150/150 [==============================] - 0s 504us/sample - loss: 0.1504 - acc: 0.9533\n",
      "Epoch 205/250\n",
      "150/150 [==============================] - 0s 518us/sample - loss: 0.5529 - acc: 0.7867\n",
      "Epoch 206/250\n",
      "150/150 [==============================] - 0s 476us/sample - loss: 0.5534 - acc: 0.7000\n",
      "Epoch 207/250\n",
      "150/150 [==============================] - 0s 462us/sample - loss: 0.1775 - acc: 0.9733\n",
      "Epoch 208/250\n",
      "150/150 [==============================] - 0s 529us/sample - loss: 0.1511 - acc: 0.9800\n",
      "Epoch 209/250\n",
      "150/150 [==============================] - 0s 473us/sample - loss: 0.1385 - acc: 0.9867\n",
      "Epoch 210/250\n",
      "150/150 [==============================] - 0s 496us/sample - loss: 0.1268 - acc: 0.9867\n",
      "Epoch 211/250\n",
      "150/150 [==============================] - 0s 481us/sample - loss: 0.1220 - acc: 0.9800\n",
      "Epoch 212/250\n",
      "150/150 [==============================] - 0s 472us/sample - loss: 0.1147 - acc: 0.9800\n",
      "Epoch 213/250\n",
      "150/150 [==============================] - 0s 510us/sample - loss: 0.1094 - acc: 0.9867\n",
      "Epoch 214/250\n",
      "150/150 [==============================] - 0s 485us/sample - loss: 0.1195 - acc: 0.9600\n",
      "Epoch 215/250\n",
      "150/150 [==============================] - 0s 469us/sample - loss: 0.1112 - acc: 0.9667\n",
      "Epoch 216/250\n",
      "150/150 [==============================] - 0s 512us/sample - loss: 0.1138 - acc: 0.9667\n",
      "Epoch 217/250\n",
      "150/150 [==============================] - 0s 480us/sample - loss: 0.1474 - acc: 0.9400\n",
      "Epoch 218/250\n",
      "150/150 [==============================] - 0s 499us/sample - loss: 0.5474 - acc: 0.7867\n",
      "Epoch 219/250\n",
      "150/150 [==============================] - 0s 510us/sample - loss: 0.1656 - acc: 0.9267\n",
      "Epoch 220/250\n",
      "150/150 [==============================] - 0s 506us/sample - loss: 0.2037 - acc: 0.9133\n",
      "Epoch 221/250\n",
      "150/150 [==============================] - 0s 510us/sample - loss: 0.2854 - acc: 0.8667\n",
      "Epoch 222/250\n",
      "150/150 [==============================] - 0s 462us/sample - loss: 0.1360 - acc: 0.9533\n",
      "Epoch 223/250\n",
      "150/150 [==============================] - 0s 481us/sample - loss: 0.2665 - acc: 0.8600\n",
      "Epoch 224/250\n",
      "150/150 [==============================] - 0s 515us/sample - loss: 0.7439 - acc: 0.7333\n",
      "Epoch 225/250\n",
      "150/150 [==============================] - 0s 496us/sample - loss: 0.7459 - acc: 0.6667\n",
      "Epoch 226/250\n",
      "150/150 [==============================] - 0s 486us/sample - loss: 0.5169 - acc: 0.6733\n",
      "Epoch 227/250\n",
      "150/150 [==============================] - 0s 515us/sample - loss: 0.3849 - acc: 0.7867\n",
      "Epoch 228/250\n",
      "150/150 [==============================] - 0s 488us/sample - loss: 0.2967 - acc: 0.9667\n",
      "Epoch 229/250\n",
      "150/150 [==============================] - 0s 533us/sample - loss: 0.2374 - acc: 0.9667\n",
      "Epoch 230/250\n",
      "150/150 [==============================] - 0s 455us/sample - loss: 0.1972 - acc: 0.9800\n",
      "Epoch 231/250\n",
      "150/150 [==============================] - 0s 537us/sample - loss: 0.1703 - acc: 0.9800\n",
      "Epoch 232/250\n",
      "150/150 [==============================] - 0s 513us/sample - loss: 0.1573 - acc: 0.9733\n",
      "Epoch 233/250\n",
      "150/150 [==============================] - 0s 454us/sample - loss: 0.1567 - acc: 0.9533\n",
      "Epoch 234/250\n",
      "150/150 [==============================] - 0s 484us/sample - loss: 0.1836 - acc: 0.9200\n",
      "Epoch 235/250\n",
      "150/150 [==============================] - 0s 520us/sample - loss: 0.2176 - acc: 0.9000\n",
      "Epoch 236/250\n",
      "150/150 [==============================] - 0s 512us/sample - loss: 0.1275 - acc: 0.9733\n",
      "Epoch 237/250\n",
      "150/150 [==============================] - 0s 489us/sample - loss: 0.1300 - acc: 0.9600\n",
      "Epoch 238/250\n",
      "150/150 [==============================] - 0s 539us/sample - loss: 0.1403 - acc: 0.9667\n",
      "Epoch 239/250\n",
      "150/150 [==============================] - 0s 472us/sample - loss: 0.1629 - acc: 0.9400\n",
      "Epoch 240/250\n",
      "150/150 [==============================] - 0s 512us/sample - loss: 0.1129 - acc: 0.9733\n",
      "Epoch 241/250\n",
      "150/150 [==============================] - 0s 493us/sample - loss: 0.1158 - acc: 0.9600\n",
      "Epoch 242/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 518us/sample - loss: 0.2245 - acc: 0.8867\n",
      "Epoch 243/250\n",
      "150/150 [==============================] - 0s 473us/sample - loss: 0.5516 - acc: 0.7800\n",
      "Epoch 244/250\n",
      "150/150 [==============================] - 0s 486us/sample - loss: 0.2824 - acc: 0.8533\n",
      "Epoch 245/250\n",
      "150/150 [==============================] - 0s 475us/sample - loss: 0.1227 - acc: 0.9933\n",
      "Epoch 246/250\n",
      "150/150 [==============================] - 0s 474us/sample - loss: 0.1172 - acc: 0.9867\n",
      "Epoch 247/250\n",
      "150/150 [==============================] - 0s 482us/sample - loss: 0.1080 - acc: 0.9800\n",
      "Epoch 248/250\n",
      "150/150 [==============================] - 0s 470us/sample - loss: 0.1058 - acc: 0.9867\n",
      "Epoch 249/250\n",
      "150/150 [==============================] - 0s 501us/sample - loss: 0.1090 - acc: 0.9667\n",
      "Epoch 250/250\n",
      "150/150 [==============================] - 0s 477us/sample - loss: 0.1271 - acc: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2358603750>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y, epochs=250,batch_size=75,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "0              5.1           3.5            1.4           0.2\n",
       "1              4.9           3.0            1.4           0.2\n",
       "2              4.7           3.2            1.3           0.2\n",
       "3              4.6           3.1            1.5           0.2\n",
       "4              5.0           3.6            1.4           0.2\n",
       "..             ...           ...            ...           ...\n",
       "145            6.7           3.0            5.2           2.3\n",
       "146            6.3           2.5            5.0           1.9\n",
       "147            6.5           3.0            5.2           2.0\n",
       "148            6.2           3.4            5.4           2.3\n",
       "149            5.9           3.0            5.1           1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=data.loc[:,\"SepalLengthCm\":\"PetalWidthCm\"]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_4_input to have shape (4,) but got array with shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-77777d4cf477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    583\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_4_input to have shape (4,) but got array with shape (5,)"
     ]
    }
   ],
   "source": [
    "df1['predict']=Y.columns.take(np.argmax(model.predict(df1),axis=1))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
